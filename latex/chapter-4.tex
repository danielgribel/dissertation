\chapter{Computational Experiments and Analysis}
In this chapter, we discuss the computational experiments and the analysis that emerge from them. The results of the proposed algorithm are presented in terms of objective function value and time, and are also compared to current state-of-the-art results in the MSSC literature.

The experiments were conducted on an Intel Core i5 2.6 GHz processor machine with 8 GB of RAM memory. The source codes were written in C++, using the UNIX g++ compiler on a Linux Ubuntu 14.04 LTS 64-bit operating system.

\section{Instances}
The selection of instances was done in order to cover different types of data, considering both the instance size and the number of features as important indicators to describe the nature of data. Table \ref{instances} summarizes the characteristics of the adopted instances, which correspond to XX important benchmarks in recent clustering literature, as reported in \cite{Ordin2014} and \cite{Bagirov2016}. For all considered instances, every feature value is a real or integer number and there is no missing values. The number of data points (instances size) ranges from 59 (smallest) to 434,874 (largest); and the number of features ranges from 2 (smallest) to 128 (largest). Thus, in order to elucidate the coming analysis, we propose the discrimination of these instances according to their sizes -- having small, medium and large sets. % and the number of features (small and large sets)

\input{tables/instances}

\section{Parameters calibration}
As in most meta-heuristics, the values chosen for parameters directly affect the results. In this work, we consider five main parameters: $\mu$ (the population size), $\eta$ (the maximum size of population), $\beta$ (the number of new individuals created in the diversification), $I$ (the number of iterations without improvement that triggers diversification) and $itNoImprovement$ (the number of iterations without improvement that causes the algorithm stop).

In preliminary experiments, we started with the following configuration, as they produced good and stable results: $\mu$ = 30, $\eta$ = 400, $\beta$ = 5, $I$ = 400 and $itNoImprovement$ = 2000. From this baseline, we expanded the range of these value. Table \ref{calibration} presents the tested values for each parameter and the final values achieved after running each combination in XX instances.

\input{tables/calibration}

\section{Results}
Results of numerical experiments for small, medium and large instances are given in tables XX, XX and XX respectively. Due to the stochastic nature of the proposed meta-heuristic, 10 runs were conducted for each configuration. The following notation is used in these tables:

\begin{itemize}

	\item $m$ is the number of clusters;

	\item $f_{best}$ is the best known value for the MSSC objective found so far;

	\item $E$ is the error, calculated as:

		\begin{center}
		\Large
			$E = \frac{f - f_{best}}{f_{best}}$
		\end{center}
		
	where $f$ is the value of the MSSC objective found by an algorithm;
	
	\item $t$ is the CPU time in seconds;

	\item Bold values corresponds to cases where the proposed meta-heuristic found the new best solution.

\end{itemize}

For comparison purposes, we also considered the results of global k-means (GKM), the modified global k-means (MGKM), the multi-start modified global k-means (MS-MGKM) and the difference of convex clustering (DCC) algorithms, that are recent works in MSSC literature, corresponding in many cases to the state-of-the-art in this problem.